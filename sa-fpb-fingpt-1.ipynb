{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== #\n",
    "# 1. Install dependencies (Kaggle does not come with these preinstalled)\n",
    "# ============================== #\n",
    "!pip install -q -U transformers accelerate peft bitsandbytes datasets scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== #\n",
    "# 2. Import Libraries\n",
    "# ============================== #\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes==0.41.1\n",
      "  Using cached bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\n",
      "Using cached bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\n",
      "Installing collected packages: bitsandbytes\n",
      "  Attempting uninstall: bitsandbytes\n",
      "    Found existing installation: bitsandbytes 0.42.0\n",
      "    Uninstalling bitsandbytes-0.42.0:\n",
      "      Successfully uninstalled bitsandbytes-0.42.0\n",
      "Successfully installed bitsandbytes-0.41.1\n",
      "CUDA available: False\n",
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n",
      "bitsandbytes info: 0.41.1\n",
      "Summary: k-bit optimizers and matrix multiplication routines.\n",
      "Home-page: https://github.com/TimDettmers/bitsandbytes\n",
      "Author: Tim Dettmers\n",
      "Author-email: dettmers@cs.washington.edu\n",
      "License: MIT\n",
      "Location: /opt/anaconda3/lib/python3.12/site-packages\n",
      "Requires: \n",
      "Required-by: \n",
      "\n",
      "Error loading model: Using `bitsandbytes` 8-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\n"
     ]
    }
   ],
   "source": [
    "# First, install or update bitsandbytes with specific version\n",
    "!pip install -U bitsandbytes==0.41.1\n",
    "\n",
    "# Make sure CUDA is available (if you're using GPU)\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# ============================== #\n",
    "# 3. Set Model and Tokenizer\n",
    "# ============================== #\n",
    "# Import necessary libraries\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import PeftModel\n",
    "import torch\n",
    "\n",
    "# Verify bitsandbytes installation\n",
    "import bitsandbytes as bnb\n",
    "# Use pip to check the version instead of accessing __version__ attribute\n",
    "import subprocess\n",
    "bnb_version = subprocess.check_output(['pip', 'show', 'bitsandbytes']).decode('utf-8')\n",
    "print(f\"bitsandbytes info: {bnb_version.split('Version: ')[1].split('\\\\n')[0]}\")\n",
    "\n",
    "base_model = \"NousResearch/Llama-2-13b-hf\"\n",
    "peft_model = \"oliverwang15/FinGPT_v33_Llama2_13B_Sentiment_Instruction_LoRA_FT_8bit\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Required for padding\n",
    "\n",
    "# Configure BitsAndBytes for 8-bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_has_fp16_weight=False\n",
    ")\n",
    "\n",
    "# Load the model with proper error handling\n",
    "try:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        device_map=\"auto\",\n",
    "        quantization_config=bnb_config,\n",
    "        torch_dtype=torch.float16\n",
    "    )\n",
    "    \n",
    "    model = PeftModel.from_pretrained(model, peft_model)\n",
    "    model.eval()\n",
    "    #print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== #\n",
    "# 4. Helper Functions\n",
    "# ============================== #\n",
    "label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
    "\n",
    "def format_example(example: dict) -> dict:\n",
    "    context = f\"Instruction: {example['instruction']}\\n\"\n",
    "    if example.get(\"input\"):\n",
    "        context += f\"Input: {example['input']}\\n\"\n",
    "    context += \"Answer: \"\n",
    "    target = example[\"output\"]\n",
    "    return {\"context\": context, \"target\": target}\n",
    "\n",
    "def change_target(x):\n",
    "    x = x.lower()\n",
    "    if 'positive' in x:\n",
    "        return 'positive'\n",
    "    elif 'negative' in x:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Here i tried Few Shot Prompting that got 60% acc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T09:47:47.667757Z",
     "iopub.status.busy": "2025-05-15T09:47:47.667526Z",
     "iopub.status.idle": "2025-05-15T09:47:47.695668Z",
     "shell.execute_reply": "2025-05-15T09:47:47.694883Z",
     "shell.execute_reply.started": "2025-05-15T09:47:47.667740Z"
    }
   },
   "outputs": [],
   "source": [
    "# def prompt_fun_few_shot(row):\n",
    "#     # Define few-shot examples (ideally 2â€“3)\n",
    "#     few_shot_prompt = (\n",
    "#         \"Determine the sentiment of the following financial news headlines. \"\n",
    "#         \"Respond with one word: Negative, Neutral, or Positive.\\n\\n\"\n",
    "#         \"Example 1:\\n\"\n",
    "#         \"Input: Company X's shares dropped after a disappointing earnings report.\\n\"\n",
    "#         \"Answer: Negative\\n\\n\"\n",
    "#         \"Example 2:\\n\"\n",
    "#         \"Input: The central bank maintained current interest rates.\\n\"\n",
    "#         \"Answer: Neutral\\n\\n\"\n",
    "#         \"Example 3:\\n\"\n",
    "#         \"Input: Tech firm Y reported record profits this quarter.\\n\"\n",
    "#         \"Answer: Positive\\n\\n\"\n",
    "#         \"Now analyze the following news:\\n\"\n",
    "#     )\n",
    "\n",
    "#     # Append the current input\n",
    "#     input_text = f\"Input: {row['input']}\\nAnswer: \"\n",
    "#     return few_shot_prompt + input_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Here tried zero shot prompting with a direct instruction that got 84% acc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T09:47:47.696719Z",
     "iopub.status.busy": "2025-05-15T09:47:47.696456Z",
     "iopub.status.idle": "2025-05-15T09:47:47.717582Z",
     "shell.execute_reply": "2025-05-15T09:47:47.716794Z",
     "shell.execute_reply.started": "2025-05-15T09:47:47.696701Z"
    }
   },
   "outputs": [],
   "source": [
    "#def better_zero_shot_prompt(row):\n",
    "  #  return (\n",
    "     #   \"Analyze the following financial news and determine the sentiment it expresses. \"\n",
    "     #   \"Choose only one: Negative, Neutral, or Positive. \"\n",
    "     #   \"Respond with only one word and no explanation.\\n\"\n",
    "      #  f\"Input: {row['input']}\\n\"\n",
    "       # \"Answer:\"\n",
    "    #)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Here i did chain of thought prompting that got 86% acc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T11:02:45.891110Z",
     "iopub.status.busy": "2025-05-15T11:02:45.890846Z",
     "iopub.status.idle": "2025-05-15T11:02:45.895119Z",
     "shell.execute_reply": "2025-05-15T11:02:45.894303Z",
     "shell.execute_reply.started": "2025-05-15T11:02:45.891085Z"
    }
   },
   "outputs": [],
   "source": [
    "def chain_of_thought_prompt(row):\n",
    "   return (\n",
    "       \"You are a financial sentiment expert. think step-by-step to determine if the following news is: Negative, Neutral, or Positive.\"\n",
    "        f\"Input: {row['input']}\\n\"\n",
    "       \"Reasoning: \"\n",
    "   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Here i did Zero Short COT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T09:47:47.735589Z",
     "iopub.status.busy": "2025-05-15T09:47:47.735326Z",
     "iopub.status.idle": "2025-05-15T09:47:47.757858Z",
     "shell.execute_reply": "2025-05-15T09:47:47.757278Z",
     "shell.execute_reply.started": "2025-05-15T09:47:47.735562Z"
    }
   },
   "outputs": [],
   "source": [
    "# def zero_shot_chain_of_thought_prompt(row):\n",
    "#     return (\n",
    "#         \"You are a financial sentiment expert. Analyze the financial news carefully and think step-by-step to determine the sentiment expressed. \"\n",
    "#         \"Consider whether the language indicates optimism, pessimism, or neutrality in the financial context. \"\n",
    "#         \"Finally, classify the sentiment using one word only: Negative, Neutral, or Positive.\\n\\n\"\n",
    "#         f\"Input: {row['input']}\\n\"\n",
    "#         \"Reasoning: \"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Automatic Chain of Thought Prompt Version:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T09:47:47.760264Z",
     "iopub.status.busy": "2025-05-15T09:47:47.760040Z",
     "iopub.status.idle": "2025-05-15T09:47:47.779667Z",
     "shell.execute_reply": "2025-05-15T09:47:47.779066Z",
     "shell.execute_reply.started": "2025-05-15T09:47:47.760249Z"
    }
   },
   "outputs": [],
   "source": [
    "# def automatic_chain_of_thought_prompt(row):\n",
    "#     return (\n",
    "#         \"You are a financial sentiment expert. Analyze the financial news carefully and think step-by-step to determine the sentiment expressed. \"\n",
    "#         \"Consider whether the language indicates optimism, pessimism, or neutrality in the financial context. \"\n",
    "#         \"Finally, classify the sentiment using one word only: Negative, Neutral, or Positive.\\n\\n\"\n",
    "        \n",
    "#         \"Example:\\n\"\n",
    "#         \"Input: The company's quarterly earnings surpassed expectations, boosting investor confidence.\\n\"\n",
    "#         \"Reasoning: The news talks about exceeding expectations and increased investor confidence, which suggests optimism.\\n\"\n",
    "#         \"Answer: Positive\\n\\n\"\n",
    "\n",
    "#         f\"Input: {row['input']}\\n\"\n",
    "#         \"Reasoning: \"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Meta Prompting Version:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T09:47:47.780686Z",
     "iopub.status.busy": "2025-05-15T09:47:47.780420Z",
     "iopub.status.idle": "2025-05-15T09:47:47.796755Z",
     "shell.execute_reply": "2025-05-15T09:47:47.796154Z",
     "shell.execute_reply.started": "2025-05-15T09:47:47.780669Z"
    }
   },
   "outputs": [],
   "source": [
    "# def meta_prompting_chain_of_thought(row):\n",
    "#     return (\n",
    "#         \"You are a financial sentiment expert. Your task is not just to classify sentiment, but to design the best reasoning strategy to do so.\\n\"\n",
    "#         \"First, decide what reasoning steps would help determine if the news expresses optimism, pessimism, or neutrality.\\n\"\n",
    "#         \"Then, apply your own strategy to analyze the input.\\n\"\n",
    "#         \"Finally, classify the sentiment using one word only: Negative, Neutral, or Positive.\\n\\n\"\n",
    "        \n",
    "#         f\"Input: {row['input']}\\n\"\n",
    "#         \"Step-by-step reasoning strategy: \\n\"\n",
    "#         \"Applied reasoning: \\n\"\n",
    "#         \"Answer: \"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Generated Knowledge Prompting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T09:47:47.797590Z",
     "iopub.status.busy": "2025-05-15T09:47:47.797399Z",
     "iopub.status.idle": "2025-05-15T09:47:47.812483Z",
     "shell.execute_reply": "2025-05-15T09:47:47.811897Z",
     "shell.execute_reply.started": "2025-05-15T09:47:47.797577Z"
    }
   },
   "outputs": [],
   "source": [
    "# def generated_knowledge_prompt(row):\n",
    "#     return (\n",
    "#         \"You are a financial sentiment expert. Your task is to first generate relevant background knowledge to help interpret the following financial statement excerpt. \"\n",
    "#         \"Then, using that knowledge, analyze the excerpt and determine the sentiment expressed (optimism, pessimism, or neutrality). \"\n",
    "#         \"Finally, classify the sentiment using one word only: Negative, Neutral, or Positive.\\n\\n\"\n",
    "        \n",
    "#         f\"Input: {row['input']}\\n\"\n",
    "        \n",
    "#         \"Generated Knowledge: \\n\"\n",
    "#         \"Step-by-step Analysis: \\n\"\n",
    "#         \"Final Answer: \"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Prompt Chaining*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T09:47:47.813346Z",
     "iopub.status.busy": "2025-05-15T09:47:47.813152Z",
     "iopub.status.idle": "2025-05-15T09:47:47.833711Z",
     "shell.execute_reply": "2025-05-15T09:47:47.833178Z",
     "shell.execute_reply.started": "2025-05-15T09:47:47.813332Z"
    }
   },
   "outputs": [],
   "source": [
    "# def prompt_chain(row):\n",
    "#     return (\n",
    "#         \"You are a financial sentiment expert. Follow the steps below:\\n\\n\"\n",
    "#         f\"Input: {row['input']}\\n\\n\"\n",
    "#         \"Step 1 - Extract the key financial facts or events mentioned in the statement.\\n\"\n",
    "#         \"Step 2 - Analyze the likely impact of these facts on the company's financial outlook.\\n\"\n",
    "#         \"Step 3 - Classify the sentiment using one word only: Negative, Neutral, or Positive.\\n\"\n",
    "#         \"Answer: \"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Tree-of-Thought Prompting*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T09:47:47.834709Z",
     "iopub.status.busy": "2025-05-15T09:47:47.834452Z",
     "iopub.status.idle": "2025-05-15T09:47:47.853393Z",
     "shell.execute_reply": "2025-05-15T09:47:47.852796Z",
     "shell.execute_reply.started": "2025-05-15T09:47:47.834693Z"
    }
   },
   "outputs": [],
   "source": [
    "# def tree_of_thought_prompt(row):\n",
    "#     return (\n",
    "#         \"You are a financial sentiment expert. Think through multiple reasoning paths to determine whether the following financial news expresses a Negative, Neutral, or Positive sentiment.\\n\\n\"\n",
    "#         f\"Input: {row['input']}\\n\\n\"\n",
    "#         \"Path 1 - Consider the impact on company revenue and profitability:\\n\"\n",
    "#         \"...\\n\\n\"\n",
    "#         \"Path 2 - Consider investor and market reactions to similar events:\\n\"\n",
    "#         \"...\\n\\n\"\n",
    "#         \"Path 3 - Consider short-term vs long-term financial implications:\\n\"\n",
    "#         \"...\\n\\n\"\n",
    "#         \"After evaluating all paths, synthesize your findings and give a final sentiment decision in one word (Negative, Neutral, or Positive).\\n\"\n",
    "#         \"Answer: \"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Hybrid Prompt*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T09:47:47.854337Z",
     "iopub.status.busy": "2025-05-15T09:47:47.854100Z",
     "iopub.status.idle": "2025-05-15T09:47:47.872247Z",
     "shell.execute_reply": "2025-05-15T09:47:47.871725Z",
     "shell.execute_reply.started": "2025-05-15T09:47:47.854322Z"
    }
   },
   "outputs": [],
   "source": [
    "# def hybrid_cot_selfconsistency_prompt(row):\n",
    "#     return (\n",
    "#         \"You are a financial sentiment expert. Carefully evaluate the sentiment in the following news article.\\n\"\n",
    "#         \"Think in multiple ways and explain your reasoning step-by-step.\\n\\n\"\n",
    "#         f\"Input: {row['input']}\\n\\n\"\n",
    "#         \"Path 1 - Analyze how the event affects profitability and earnings:\\n\"\n",
    "#         \"...\\n\\n\"\n",
    "#         \"Path 2 - Consider the market and investor reaction to similar events:\\n\"\n",
    "#         \"...\\n\\n\"\n",
    "#         \"Path 3 - Evaluate the long-term vs short-term financial implications:\\n\"\n",
    "#         \"...\\n\\n\"\n",
    "#         \"Synthesize your thoughts across the paths. Then, classify the sentiment with one word only: Negative, Neutral, or Positive.\\n\"\n",
    "#         \"Answer: \"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *refined Zero-Shot CoT*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-15T09:47:47.873355Z",
     "iopub.status.busy": "2025-05-15T09:47:47.873060Z",
     "iopub.status.idle": "2025-05-15T09:47:47.896514Z",
     "shell.execute_reply": "2025-05-15T09:47:47.895798Z",
     "shell.execute_reply.started": "2025-05-15T09:47:47.873336Z"
    }
   },
   "outputs": [],
   "source": [
    "# def best_prompt(row):\n",
    "#     return (\n",
    "#         \"You are a financial sentiment expert. Analyze the financial news below and determine the sentiment.\\n\"\n",
    "#         \"Think step-by-step and explain your reasoning. Then give your final sentiment in one word: Negative, Neutral, or Positive.\\n\\n\"\n",
    "#         f\"News: {row['input']}\\n\\n\"\n",
    "#         \"Reasoning:\"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Here was the standard prompting that got 88% - 87% acc*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================== #\n",
    "# 5. Main Evaluation Function\n",
    "# ============================== #\n",
    "def test_fpb(model, tokenizer, batch_size=4, prompt_fun=None):\n",
    "    data = load_dataset(\"financial_phrasebank\", \"sentences_50agree\")[\"train\"]\n",
    "    data = data.train_test_split(seed=42)['test']\n",
    "    df = data.to_pandas()\n",
    "    df.columns = [\"input\", \"output\"]\n",
    "    df[\"output\"] = df[\"output\"].apply(lambda x: label_map[x])\n",
    "\n",
    "    if prompt_fun is None:\n",
    "        df[\"instruction\"] = \"What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\"\n",
    "    else:\n",
    "        df[\"instruction\"] = df.apply(prompt_fun, axis=1)\n",
    "\n",
    "    df[[\"context\", \"target\"]] = df.apply(format_example, axis=1, result_type=\"expand\")\n",
    "\n",
    "    print(f\"\\nPrompt Example:\\n{df['context'].iloc[0]}\\n\")\n",
    "\n",
    "    context = df['context'].tolist()\n",
    "    total_steps = len(context) // batch_size + 1\n",
    "\n",
    "    print(f\"Evaluating {len(context)} samples with batch size {batch_size}...\")\n",
    "\n",
    "    out_text_list = []\n",
    "    for i in tqdm(range(total_steps)):\n",
    "        tmp_context = context[i * batch_size:(i + 1) * batch_size]\n",
    "        if not tmp_context:\n",
    "            continue\n",
    "        tokens = tokenizer(tmp_context, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        tokens = {k: v.cuda() for k, v in tokens.items()}\n",
    "        with torch.no_grad():\n",
    "            res = model.generate(**tokens, max_length=512, pad_token_id=tokenizer.eos_token_id)\n",
    "        decoded = tokenizer.batch_decode(res, skip_special_tokens=True)\n",
    "        extracted = [text.split(\"Answer: \")[-1].strip() for text in decoded]\n",
    "        out_text_list.extend(extracted)\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    df[\"out_text\"] = out_text_list\n",
    "    df[\"new_target\"] = df[\"target\"].apply(change_target)\n",
    "    df[\"new_out\"] = df[\"out_text\"].apply(change_target)\n",
    "\n",
    "    acc = accuracy_score(df[\"new_target\"], df[\"new_out\"])\n",
    "    f1_macro = f1_score(df[\"new_target\"], df[\"new_out\"], average=\"macro\")\n",
    "    f1_micro = f1_score(df[\"new_target\"], df[\"new_out\"], average=\"micro\")\n",
    "    f1_weighted = f1_score(df[\"new_target\"], df[\"new_out\"], average=\"weighted\")\n",
    "\n",
    "    print(f\"\\nâœ… Evaluation Results:\")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1 Macro: {f1_macro:.4f}\")\n",
    "    print(f\"F1 Micro: {f1_micro:.4f}\")\n",
    "    print(f\"F1 Weighted: {f1_weighted:.4f}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ============================== #\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 6. Run Evaluation\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ============================== #\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#results_df = test_fpb(model, tokenizer, batch_size=4)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m instructions_df \u001b[38;5;241m=\u001b[39m test_fpb(model, tokenizer, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, prompt_fun\u001b[38;5;241m=\u001b[39mchain_of_thought_prompt)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================== #\n",
    "# 6. Run Evaluation\n",
    "# ============================== #\n",
    "#results_df = test_fpb(model, tokenizer, batch_size=4)\n",
    "\n",
    "instructions_df = test_fpb(model, tokenizer, batch_size=8, prompt_fun=chain_of_thought_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-05-15T09:47:47.937283Z",
     "iopub.status.idle": "2025-05-15T09:47:47.937614Z",
     "shell.execute_reply": "2025-05-15T09:47:47.937449Z",
     "shell.execute_reply.started": "2025-05-15T09:47:47.937433Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Define class labels explicitly\n",
    "class_labels = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "# Generate the confusion matrix\n",
    "#cm = confusion_matrix(results_df[\"new_target\"], results_df[\"new_out\"], labels=class_labels)\n",
    "cm = confusion_matrix(instructions_df[\"new_target\"], instructions_df[\"new_out\"], labels=class_labels)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
    "disp.plot(cmap='Blues', ax=ax, values_format='d')\n",
    "\n",
    "plt.title(\"Confusion Matrix - FinGPT Sentiment Classification\")\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
